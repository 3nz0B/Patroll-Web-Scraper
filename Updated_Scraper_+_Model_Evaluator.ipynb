{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPOOPtNeIjvc0zgoynuabJG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brianh27/Patroll-Web-Scraper/blob/main/Updated_Scraper_%2B_Model_Evaluator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scraper (automatically converts iutput to JSON format)"
      ],
      "metadata": {
        "id": "WHtm6gyVscRP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SmLqaE4NsQ1q"
      },
      "outputs": [],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import json\n",
        "\n",
        "from contest_title import contest_title\n",
        "from prior_art import prior_art\n",
        "\n",
        "# Set up headless Chrome for main navigation\n",
        "options = Options()\n",
        "options.add_argument(\"--headless\")\n",
        "options.add_argument(\"--window-size=1920,1080\")\n",
        "driver = webdriver.Chrome(options=options)\n",
        "\n",
        "# Set up separate scraper driver for contest detail pages\n",
        "scraper = webdriver.Chrome(options=options)\n",
        "\n",
        "# Target URL\n",
        "url = \"https://patroll.unifiedpatents.com/contests?category=won\"\n",
        "driver.get(url)\n",
        "\n",
        "# Data containers\n",
        "results = []\n",
        "max_pages = 19\n",
        "prefix = 'https://www.google.com'\n",
        "\n",
        "try:\n",
        "    for page_num in range(1, max_pages + 1):\n",
        "        print(f\"üîÑ Processing page {page_num}...\")\n",
        "\n",
        "        time.sleep(1)\n",
        "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
        "        ul = soup.find(\"ul\", class_=\"ant-list-items\")\n",
        "\n",
        "        if not ul:\n",
        "            break\n",
        "\n",
        "        # Extract links\n",
        "        temp_links = [a['href'] for a in ul.find_all('a', href=True)]\n",
        "        contest_links = [\"https://patroll.unifiedpatents.com\" + link for link in temp_links if link.startswith('/contests/')]\n",
        "        troll_patents = [link.split('/')[-1] for link in temp_links if link.startswith(prefix)]\n",
        "\n",
        "        for idx, contest_url in enumerate(contest_links):\n",
        "            print(f\"üîç Contest #{idx+1}: {contest_url}\")\n",
        "            try:\n",
        "                title = contest_title(contest_url, scraper)\n",
        "            except:\n",
        "                title = \"N/A\"\n",
        "\n",
        "            try:\n",
        "                prior_arts = prior_art(contest_url, scraper)\n",
        "            except:\n",
        "                prior_arts = []\n",
        "\n",
        "            parsed_prior_art = []\n",
        "            for art in prior_arts:\n",
        "                parsed_prior_art.append({\n",
        "                    \"patent_id\": art,\n",
        "                    \"country_code\": art[:2]  # US, EP, WO, etc.\n",
        "                })\n",
        "\n",
        "            results.append({\n",
        "                \"contest_title\": title,\n",
        "                \"troll_patent_id\": troll_patents[idx] if idx < len(troll_patents) else \"N/A\",\n",
        "                \"prior_art_patents\": parsed_prior_art,\n",
        "                \"contest_url\": contest_url\n",
        "            })\n",
        "\n",
        "        # Click \"Next Page\"\n",
        "        try:\n",
        "            next_button = WebDriverWait(driver, 10).until(\n",
        "                EC.element_to_be_clickable((By.CSS_SELECTOR, \"li.ant-pagination-next[title='Next Page']\"))\n",
        "            )\n",
        "            driver.execute_script(\"arguments[0].scrollIntoView();\", next_button)\n",
        "            driver.execute_script(\"arguments[0].click();\", next_button)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Could not find/click 'Next Page' button: {e}\")\n",
        "            break\n",
        "\n",
        "finally:\n",
        "    driver.quit()\n",
        "    scraper.quit()\n",
        "\n",
        "    # Write JSON\n",
        "    with open(\"scraped_patents.json\", \"w\") as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "    print(\"\\n‚úÖ Data saved to 'scraped_patents.json'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scraper Evaluator (Using Openpxyl workspace)"
      ],
      "metadata": {
        "id": "lQRtB-VrseKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openpyxl\n",
        "\n",
        "def simulated_patent_search(base_patent: str, winning_patents: list, prior_art_list: list):\n",
        "    winning_set = set(p.upper() for p in winning_patents)\n",
        "    found_set = set(p.upper() for p in prior_art_list)\n",
        "    found_matches = list(winning_set & found_set)\n",
        "    success = len(found_matches) > 0\n",
        "    return found_matches, success\n",
        "\n",
        "# Load workbook\n",
        "excel_path = \"PatentPlusAI Week 2 Deliverable.xlsx\"\n",
        "wb = openpyxl.load_workbook(excel_path)\n",
        "sheet = wb[\"Scraped Contests\"]\n",
        "\n",
        "# ‚úÖ Replace this with real known answers (mock example below)\n",
        "ground_truth = {\n",
        "    \"US1234567B2\": [\"US7654321B1\", \"US9999999A1\"],\n",
        "    \"US2468135B2\": [\"US1357924A1\", \"US9876543B2\"],\n",
        "    # Add more known contest-patent mappings here\n",
        "}\n",
        "\n",
        "# Initialize metrics\n",
        "total = 0\n",
        "success_count = 0\n",
        "recall_scores = []\n",
        "hit_counts = []\n",
        "\n",
        "for row in sheet.iter_rows(min_row=2, values_only=True):\n",
        "    troll_patent, prior_art_str, _, _, _ = row\n",
        "    if not troll_patent or troll_patent not in ground_truth:\n",
        "        continue  # Skip rows without known ground truth\n",
        "\n",
        "    scraped_prior_art = [pat.strip().upper() for pat in prior_art_str.split(\",\") if pat.strip()]\n",
        "    correct_prior_art = [p.upper() for p in ground_truth[troll_patent]]\n",
        "\n",
        "    found, success = simulated_patent_search(troll_patent, correct_prior_art, scraped_prior_art)\n",
        "\n",
        "    # ‚úÖ Calculate recall\n",
        "    true_positives = len(found)\n",
        "    recall = true_positives / len(correct_prior_art) if correct_prior_art else 0\n",
        "\n",
        "    recall_scores.append(recall)\n",
        "    hit_counts.append(true_positives)\n",
        "\n",
        "    if success:\n",
        "        success_count += 1\n",
        "    total += 1\n",
        "\n",
        "# ‚úÖ Final metrics\n",
        "accuracy = (success_count / total) * 100 if total else 0\n",
        "mean_recall = sum(recall_scores) / len(recall_scores) if recall_scores else 0\n",
        "average_hits = sum(hit_counts) / len(hit_counts) if hit_counts else 0\n",
        "\n",
        "# üçü Results\n",
        "print(f\"\\nüìä Evaluation Metrics:\")\n",
        "print(f\"Total Contests Evaluated: {total}\")\n",
        "print(f\"‚úÖ Success Rate: {accuracy:.2f}%\")\n",
        "print(f\"üìà Average Recall: {mean_recall:.2f}\")\n",
        "print(f\"üéØ Average Ground Truth Hits: {average_hits:.2f} per contest\")\n"
      ],
      "metadata": {
        "id": "Mf6-CvmWsowH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}